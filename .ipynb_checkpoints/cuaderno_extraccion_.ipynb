{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93da316-9048-4d02-ac1f-5b11ef3e3f18",
   "metadata": {},
   "source": [
    "## TV Shows API\n",
    "\n",
    "Utilizaremos la TV Shows API como fuente de datos real para obtener la información de los shows.\n",
    "El objetivo es transformar esta información dispersa en un **pd.DataFrame** estructurado y listo para el análisis, \n",
    "realizando las siguientes etapas:\n",
    "\n",
    "### Extracción de Datos:\n",
    "Define una función que extraiga los datos de todos los shows y retorne dicha información en una lista, \n",
    "donde cada elemento de la lista es un diccionario con la información de cada serie.\n",
    "Usa como fuente de datos el API  (_**https://www.episodate.com/api/show-details?q={show_id}**_)\n",
    "\n",
    "- **notebook de extraccion nos dividimos el trabajo de la siguiente forma:**\n",
    "  -            indice_1 indice_2\n",
    "  - Belen   =   1,       18986+1\n",
    "  - Carlos  =   18986,   37971+1\n",
    "  - Eduardo =   37972,   56937+1\n",
    "  - Horacio =   56938,   75923+1\n",
    "  - Julio   =   75924,   94926+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d28ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todo listo\n"
     ]
    }
   ],
   "source": [
    "# 1. Importar librerías\n",
    "import requests, pandas as pd, numpy as np, time\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Todo listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136fec5-6f06-4dbc-8093-a4b5c960ae45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37980 episodios\n"
     ]
    }
   ],
   "source": [
    "# Primero extaemos la info\n",
    "def detalles_serie(show_id):\n",
    "    url = f\"https://www.episodate.com/api/show-details?q={show_id}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        time.sleep(0.1)\n",
    "        return r.json().get('tvShow', {})\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "shows_info = []\n",
    "todos_episodios = []\n",
    "max_number = 94926 #en teoria podriamos sacar toda esta info, tiempo estimado 24 horas\n",
    "realistic_number =  56937 #en la practica vamos a sacar esta info\n",
    "for i in range(37972, realistic_number +1):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"{i} episodios\")\n",
    "    \n",
    "    info = detalles_serie(i)\n",
    "    if not info: \n",
    "        continue\n",
    "    \n",
    "    shows_info.append({\n",
    "        'id': info.get('id'),\n",
    "        'name': info.get('name'),\n",
    "        'status': info.get('status'),\n",
    "        'start_date': info.get('start_date'),\n",
    "        'end_date': info.get('end_date'),\n",
    "        'network': info.get('network'),\n",
    "        'country': info.get('country'),\n",
    "        'runtime': info.get('runtime'),\n",
    "        'rating': info.get('rating'),\n",
    "        'rating_count': info.get('rating_count'),\n",
    "        'genres': ', '.join(info.get('genres', [])),\n",
    "        'total_episodes': len(info.get('episodes', []))\n",
    "    })\n",
    "    \n",
    "    for ep in info.get('episodes', []):\n",
    "        ep['show_id'] = info['id']\n",
    "    todos_episodios.extend(info.get('episodes', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Guardar CSV 1: Info de series\n",
    "df_shows = pd.DataFrame(shows_info)\n",
    "df_shows.to_csv(\"01_shows_master.csv\", index=False)\n",
    "print(\"Guardado 01_shows_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Guardar CSV 2: Todos los episodios\n",
    "df_eps = pd.DataFrame(todos_episodios)\n",
    "df_eps.to_csv(\"02_episodios_raw.csv\", index=False)\n",
    "print(\"Guardado 02_episodios_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35981283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los archivos CSV\n",
    "file1_path = '01_shows_master_belen.csv'\n",
    "file2_path = '01_shows_master_carlos.csv'\n",
    "file3_path = '01_shows_master_eduardo.csv'\n",
    "file4_path = '01_shows_master_horacio.csv'\n",
    "file5_path = '01_shows_master_julio.csv'\n",
    "\n",
    "\n",
    "completo_path = 'csv_shows_master_extraccion.csv'\n",
    "\n",
    "# Cargar los archivos en DataFrames\n",
    "try:\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "    df3 = pd.read_csv(file3_path)\n",
    "    df4 = pd.read_csv(file4_path)\n",
    "    df5 = pd.read_csv(file5_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenar los DataFrames (unir por filas)\n",
    "    df_concatenado = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "\n",
    "    # Guardar el DataFrame resultante en un nuevo CSV\n",
    "    df_concatenado.to_csv(completo_path, index=False)\n",
    "\n",
    "    print(f\"Archivos unidos y guardados en: {completo_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\" Error: Asegúrate de que los archivos CSV existan en la ruta especificada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee35c87-b471-4c39-bf57-24143d94614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los archivos CSV\n",
    "file1_path = '02_episodios_raw_belen.csv'\n",
    "file2_path = '02_episodios_raw_carlos.csv'\n",
    "file3_path = '02_episodios_raw_edu.csv'\n",
    "file4_path = '02_episodios_raw_horacio.csv'\n",
    "file5_path = '02_episodios_raw_julio.csv'\n",
    "\n",
    "\n",
    "completo_path = 'csv_episodios_raw__extraccion.csv'\n",
    "\n",
    "# Cargar los archivos en DataFrames\n",
    "try:\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "    df3 = pd.read_csv(file3_path)\n",
    "    df4 = pd.read_csv(file4_path)\n",
    "    df5 = pd.read_csv(file5_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenar los DataFrames (unir por filas)\n",
    "    df_concatenado = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "\n",
    "    # Guardar el DataFrame resultante en un nuevo CSV\n",
    "    df_concatenado.to_csv(completo_path, index=False)\n",
    "\n",
    "    print(f\"Archivos unidos y guardados en: {completo_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\" Error: Asegúrate de que los archivos CSV existan en la ruta especificada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
