{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319de475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar librerías - Empieza la vaina\n",
    "import requests, pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, time\n",
    "from datetime import datetime\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "print(\"Todo listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf57d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Buscar cientos de series con paginación\n",
    "def buscar_series(paginas=50):\n",
    "    series = []\n",
    "    for p in range(1, paginas+1):\n",
    "        print(f\"Página {p}\", end=\"\\r\")\n",
    "        url = f\"https://www.episodate.com/api/search?q=show&page={p}\"\n",
    "        try:\n",
    "            data = requests.get(url).json().get('tv_shows', [])\n",
    "            if not data: break\n",
    "            series.extend(data)\n",
    "            time.sleep(0.2)\n",
    "        except: continue\n",
    "    print(f\"\\nSeries encontradas: {len(series)}\")\n",
    "    return series\n",
    "\n",
    "series_lista = buscar_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c089f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Obtener detalles completos de una serie\n",
    "def detalles_serie(show_id):\n",
    "    url = f\"https://www.episodate.com/api/show-details?q={show_id}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        time.sleep(0.35)\n",
    "        return r.json().get('tvShow', {})\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Procesar todas las series \n",
    "shows_info = []\n",
    "todos_episodios = []\n",
    "\n",
    "for i, s in enumerate(series_lista):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"{i}/{len(series_lista)} → {len(todos_episodios)} episodios\")\n",
    "    \n",
    "    info = detalles_serie(s['id'])\n",
    "    if not info: continue\n",
    "    \n",
    "    shows_info.append({\n",
    "        'id': info.get('id'),\n",
    "        'name': info.get('name'),\n",
    "        'status': info.get('status'),\n",
    "        'network': info.get('network'),\n",
    "        'country': info.get('country'),\n",
    "        'rating': info.get('rating'),\n",
    "        'genres': ', '.join(info.get('genres', [])),\n",
    "        'total_episodes': len(info.get('episodes', []))\n",
    "    })\n",
    "    \n",
    "    for ep in info.get('episodes', []):\n",
    "        ep['show_id'] = s['id']\n",
    "        ep['show_name'] = s['name']\n",
    "    todos_episodios.extend(info.get('episodes', []))\n",
    "\n",
    "print(f\"\\n¡Terminado! {len(shows_info)} series | {len(todos_episodios)} episodios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Guardar CSV 1: Info de series\n",
    "df_shows = pd.DataFrame(shows_info)\n",
    "df_shows.to_csv(\"01_shows_master.csv\", index=False)\n",
    "print(\"Guardado 01_shows_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Guardar CSV 2: Todos los episodios\n",
    "df_eps = pd.DataFrame(todos_episodios)\n",
    "df_eps.to_csv(\"02_episodios_raw.csv\", index=False)\n",
    "print(\"Guardado 02_episodios_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd228390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Cargar y mergear\n",
    "shows = pd.read_csv(\"01_shows_master.csv\")\n",
    "eps = pd.read_csv(\"02_episodios_raw.csv\")\n",
    "\n",
    "eps['air_date'] = pd.to_datetime(eps['air_date'], errors='coerce')\n",
    "eps = eps.dropna(subset=['air_date'])\n",
    "\n",
    "df = eps.merge(shows[['id','network','country','status','rating','genres']], \n",
    "                left_on='show_id', right_on='id', how='left')\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df['year'] = df['air_date'].dt.year\n",
    "print(f\"Dataset final: {df.shape[0]} episodios enriquecidos\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
