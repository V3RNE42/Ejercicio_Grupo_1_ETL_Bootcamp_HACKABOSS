{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bed862",
   "metadata": {},
   "source": [
    "# Proyecto Colaborativo\n",
    "\n",
    "> El proyecto consiste en el desarrollo de un proceso ETL básico con el objetivo de realizar un análisis estadístico de datos.\n",
    "\n",
    "## ETL - Extract, Transform, Load\n",
    "\n",
    "Un proceso (o pipeline) ETL es una secuencia de operaciones de **descarga, transformación y carga de datos**. La estructura de un ETL, por lo tanto, se desarrolla de manera secuencial.\n",
    "- Primero realizamos una **extracción automatizada** de información desde alguna fuente de datos, típicamente una **base de datos o API**.\n",
    "- Una vez los datos están todos extraídos, **se procesan** para facilitar las tareas para las cuales se van a utilizar estos datos. Por ejemplo, podemos transformar nuestros datos de una estructura de dos tablas relacionadas entre sí, en una estructura de una única tabla combinada. Durante esta etapa también se realiza la **limpieza de datos**, que consiste en ajustar la información a un formato fácilmente procesable (ej. convertir strings de fechas a objetos `datetime`, convertir valores como `--` o `?` en `np.nan` para facilitar análisis de valores perdidos, etc.).\n",
    "- Cuando los datos ya están transformados y listos para el caso de uso, se almacenan conservando este nuevo formato, con el objetivo de no repetir todo el proceso de extracción y transformación de nuevo cada vez que se quieran utilizar. El almacenamiento típicamente se realiza en una **base de datos**, o estructuras de almacenamiento más permisivas como **data lakes** y **sistemas de ficheros**. Esto último dependerá de la naturaleza de la información y de las restricciones técnicas y económicas del proyecto.\n",
    "\n",
    "Existen dos formas comunes de diseñar e implementar un proceso ETL:\n",
    "- La primera, y la más fácil, es una en la que extraemos todos los datos, luego procesamos todo, y luego almacenamos todo.\n",
    "- La segunda, un poco más difícil, pero a la vez robusta a grandes volúmenes de datos, consiste en procesar y almacenar la información sobre la marcha, mientras se está extrayendo.\n",
    "\n",
    "## Fases del proyecto\n",
    "\n",
    "En este proyeco se espera la implementación completa de una pipeline ETL destinada a facilitar un análisis de datos de cara a un cliente final. Estas son las fases del proyecto:\n",
    "\n",
    "- **ETL**: Realizamos el proceso descrito anteriormente, mediante la técnica de implementación que prefieran. La fuente de datos debe ser una o varias API(s) pública(s) a elección del equipo y validada según el criterio del docente. Los datos se almacenarán en el sistema de ficheros del ordenador.\n",
    "- **Análisis de Datos**: Con los datos transformados y almacenados, se tiene que realizar un estudio y análisis de la información que contienen. El estudio tiene que tener un foco claro y unas preguntas objetivo que se desean responder. El estudio tiene que comprender la exploración de la información y la presentación de visualizaciones y medidas estadísticas que ayuden a responder a las preguntas objetivo.\n",
    "- **Entrega**: La entrega del proyecto se realizará a través del correo electrónico. Un representante del equipo enviará un email adjuntando el enlace al repositorio público de GitHub (u otro servicio cloud de Git, Como GitLab, BitBucket o Codeberg). En el repositorio tienen que estar presentes todos los notebooks utilizados para el trabajo, bien estructurados e idealmente enumerados en orden de ejecución para todo aquel que quiera probar el código. Es importante el uso correcto de `.gitignore` para evitar saturar el repositorio con ficheros y carpetas que no aporten valor al trabajo, así como para escribir en un fichero ignorado información sensible como credenciales de las APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571605a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"€ 100.000,00\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
